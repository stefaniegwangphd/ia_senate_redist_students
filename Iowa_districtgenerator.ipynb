{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7cd18f8",
   "metadata": {},
   "source": [
    "forked Iowa_contiguousdistricting notebook on December 6\n",
    "\n",
    "Manually implementing algorithm described in Chen and Rodden (2013) in Steps 1-3 in Helper Functions subsection\n",
    "\n",
    "Shapefile dataframes used in this notebook:\n",
    "- shapefile_iowa: MGGG stuff merged with census stuff\n",
    "- shapef_ia_proj: projected to UTM so we can run distance calculations on it\n",
    "- shapef_ia_fordistricting: 99 rows for each county, ready for initial allocation; made from deep copy of shapef_ia_proj\n",
    "- shapef_counties_for_realloc: made from a deep copy from shapef_ia_fordistricting; this has a num_switches column and a district column populated with the district assignment from the initial allocation\n",
    "- shapef_ia_initialdistricting: came from _fordistricting, went through the districting (step 1/2) process, and is now 4 rows\n",
    "\tas of Sept 18, not modified further for step 3/district balancing\n",
    "- shapef_ia_redist: this is a deep copy of shapef_ia_initialdistricting with a few dropped columns. This df is used for making new districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f457be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import glob\n",
    "import os       #mkdir\n",
    "from scipy.sparse import csgraph #for laplacian\n",
    "from scipy.linalg import null_space\n",
    "from plotnine import (ggplot, aes, geom_map, geom_text, geom_label,\n",
    "                     ggtitle, element_blank, element_rect,\n",
    "                     scale_fill_manual, theme_minimal, theme, scale_fill_cmap)\n",
    "import math         ##for math.sqrt\n",
    "import random       #for random selection of district to start with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed8fb8bd",
   "metadata": {},
   "source": [
    "## Importing and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21899131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#census.csv is data from Secretary of State's office.\n",
    "census_df=pd.read_csv('census.csv')\n",
    "census_df['COUNTYFP10']=census_df['COUNTYFP10'].astype(str).str.pad(3,fillchar='0')\n",
    "\n",
    "#imports county shapefiles from MGGG\n",
    "shapefile_iowa = gpd.read_file('IA_counties/IA_counties.shp').sort_values('NAME10',ignore_index=True)\n",
    "\n",
    "## Merging ONLY 2020 population numbers and county_id from census df into shapefile_iowa\n",
    "shapefile_iowa = shapefile_iowa.merge(census_df[['COUNTYFP10','population','county_id']], on='COUNTYFP10').copy()\n",
    "\n",
    "county_populations = np.array(census_df['population'])\n",
    "state_population = sum(county_populations)\n",
    "\n",
    "#Then project the shapefiles to UTM 15N\n",
    "shapef_ia_proj = shapefile_iowa.to_crs(epsg=26915)\n",
    "\n",
    "## Merging ONLY lat/long + county id from census df into shapefile_iowa (since population and county_id are already there)\n",
    "map_population_by_county_data = shapefile_iowa.merge(census_df[['COUNTYFP10','latitude','longitude']], on='COUNTYFP10').copy()\n",
    "\n",
    "# adding/fixing columns with (projected) centroid locations \n",
    "shapef_ia_proj['xcentr_lon'] = shapef_ia_proj.centroid.x\n",
    "shapef_ia_proj['ycentr_lat'] = shapef_ia_proj.centroid.y\n",
    "\n",
    "## cutting out other columns from the shapefile to be dissolved on\n",
    "\n",
    "districting_columns = ['COUNTYFP10', 'NAME10', 'geometry', \n",
    "       'population', 'county_id', 'xcentr_lon', 'ycentr_lat']\n",
    "\n",
    "#make a new shapefile, which will be merged/dissolved on in the process of making districts\n",
    "shapef_ia_fordistricting = shapef_ia_proj[districting_columns].copy()\n",
    "\n",
    "#add column of county indices (which will get concatenated, as county_id_string)\n",
    "shapef_ia_fordistricting['county_id_string'] = shapef_ia_fordistricting['county_id']\n",
    "shapef_ia_fordistricting['county_id_string'] = shapef_ia_fordistricting['county_id_string'].astype(str).str.pad(2,fillchar='0')\n",
    "\n",
    "#add column of county indices (which will become district indices)\n",
    "shapef_ia_fordistricting['temp_district'] = shapef_ia_fordistricting.index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd125cb7",
   "metadata": {},
   "source": [
    "## Nearest-Neighbor district-building model (adjacency matrix + distance matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56b5747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for arbitrary adjacency matrix\n",
    "# updated to no longer classify kitty-corner as \"adjacent\", Oct 30\n",
    "\n",
    "def adj_mat_calc(temp_shapefile):\n",
    "    curr_n_districts = len(temp_shapefile)\n",
    "    adjac_mat = pd.DataFrame()\n",
    "\n",
    "    for i in range(curr_n_districts):\n",
    "        adjac_mat[i] = temp_shapefile.intersection(temp_shapefile.iloc[[i]].unary_union).length\n",
    "    \n",
    "    #sign function turns all nonzero entries to 1\n",
    "    adjac_mat = np.sign(adjac_mat)\n",
    "\n",
    "    #eliminate diagonals, so county i is not adjacent to itself\n",
    "    adjac_mat = adjac_mat - np.identity(curr_n_districts)\n",
    "\n",
    "    # make everything an integer\n",
    "    adjac_mat = adjac_mat.astype(int)\n",
    "\n",
    "    #and/or boolean?\n",
    "    # ia_adjac_matrix_bool = ia_adjac_matrix.astype(bool)\n",
    "\n",
    "    return adjac_mat\n",
    "\n",
    "\n",
    "#function: input is a shapefile with centroid columns, output is a distance matrix\n",
    "def temp_distance_matrix(temp_shapefile):\n",
    "    curr_n_districts = len(temp_shapefile)\n",
    "    distance_mat = np.zeros((curr_n_districts,curr_n_districts))\n",
    "\n",
    "    for i in range(curr_n_districts):\n",
    "        for j in range(i):      #just do half the triangle, so indices from 0 to i-1\n",
    "            x_dist = (temp_shapefile['xcentr_lon'].iloc[i] - temp_shapefile['xcentr_lon'].iloc[j])\n",
    "            y_dist = (temp_shapefile['ycentr_lat'].iloc[i] - temp_shapefile['ycentr_lat'].iloc[j])\n",
    "            distance_mat[i,j] = math.sqrt(x_dist**2 + y_dist**2)\n",
    "            distance_mat[j,i] = math.sqrt(x_dist**2 + y_dist**2)\n",
    "\n",
    "    return distance_mat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bc14831",
   "metadata": {},
   "source": [
    "## Steps 1 and 2 initial allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee65877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure random seed works okay inside function\n",
    "def initial_alloc_func(shapef_ia_fordistricting):\n",
    "    shapef_ia_initialdistricting = shapef_ia_fordistricting.copy()\n",
    "\n",
    "    for i in range(n_counties - n_districts): # 95 iterations brings us from 99 districts to 4\n",
    "        #how many districts are we working with this time?\n",
    "        running_ndistricts = len(shapef_ia_initialdistricting)\n",
    "\n",
    "        # pick out a district to work on on this iteration of the loop\n",
    "        running_index = random.randint(0,running_ndistricts-1)        \n",
    "\n",
    "        #find the temp_district associated with the running index\n",
    "        #     the below was returning a slice of a dataframe, and not just the entry\n",
    "        # running_temp_dist = shapef_ia_initialdistricting.loc[shapef_ia_initialdistricting.index == running_index, 'temp_district']\n",
    "        running_temp_district = shapef_ia_initialdistricting['temp_district'].iloc[running_index]\n",
    "        #     originally just called this for the print statement\n",
    "            \n",
    "        #set up adjacency and distance matrices\n",
    "        running_adjmat = adj_mat_calc(shapef_ia_initialdistricting)\n",
    "        running_distmat = temp_distance_matrix(shapef_ia_initialdistricting)\n",
    "\n",
    "        # print(\"On loop # %d (with %d districts remaining), we have selected index %d. \\\n",
    "        # \\n This corresponds to county id %s and temporary district # %d.\"   \\\n",
    "        #     % (i+1, running_ndistricts,running_index,   \\\n",
    "        #        shapef_ia_initialdistricting['county_id_string'].iloc[running_index], \\\n",
    "        #        running_temp_district) )\n",
    "\n",
    "        distance_list = list(running_distmat[running_index])\n",
    "\n",
    "        neighbor_dist = sorted(distance_list)[1]        #second smallest distance is nearest neighbor (since distance to self is zero)\n",
    "        neighbor_index = distance_list.index(neighbor_dist)   \n",
    "        \n",
    "        # the temp_district number associated with the neighbor_index\n",
    "        neighbor_temp_district= shapef_ia_initialdistricting['temp_district'].iloc[neighbor_index]\n",
    "        #   this doesn't really get used except to print? but running_temp_district is super important for re-indexing\n",
    "\n",
    "        # print(\"The nearest neighbor index is %d, representing county id %s and temporary district # %d.\" \\\n",
    "        #     % (neighbor_index,   \\\n",
    "        #        shapef_ia_initialdistricting['county_id_string'].iloc[neighbor_index],\\\n",
    "        #        neighbor_temp_district) )\n",
    "\n",
    "        # re-index the neighbor county to be in the first county's district\n",
    "        shapef_ia_initialdistricting.loc[shapef_ia_initialdistricting.index == neighbor_index, 'temp_district'] = running_temp_district      \n",
    "\n",
    "\n",
    "        # dissolve shapefile based on temp_district to combine the two counties\n",
    "        #aggregate remaining columns by summing them\n",
    "\n",
    "        # arguments for aggfunc: https://geopandas.org/en/stable/docs/user_guide/aggregation_with_dissolve.html\n",
    "        shapef_ia_initialdistricting = shapef_ia_initialdistricting.dissolve(\n",
    "            by=\"temp_district\",\n",
    "            aggfunc = {\n",
    "                \"COUNTYFP10\": \"sum\",    #sum = concatenation here b/c string\n",
    "                \"NAME10\": \"count\",      #kind of dummy: will be 2 only for most-recently-merged district\n",
    "                \"population\": \"sum\",\n",
    "                \"county_id\": \"sum\",     #should be actual sum here, kind of dummy\n",
    "                \"xcentr_lon\": \"first\",  #dummy, since we'll recalculate\n",
    "                \"ycentr_lat\": \"first\",\n",
    "                \"county_id_string\": \"sum\", #sum = concatenation here b/c string\n",
    "                \"temp_district\": \"first\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # update centroid lat/longs!\n",
    "        shapef_ia_initialdistricting['xcentr_lon'] = shapef_ia_initialdistricting.centroid.x\n",
    "        shapef_ia_initialdistricting['ycentr_lat'] = shapef_ia_initialdistricting.centroid.y\n",
    "\n",
    "        #the dissolve process makes the temp_district column into the index of the dataframe\n",
    "        #which then has issues when we iterate, so dump the index for a dummy one now\n",
    "        shapef_ia_initialdistricting = shapef_ia_initialdistricting.reset_index(drop=True)\n",
    "    \n",
    "    return(shapef_ia_initialdistricting)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c3dccbe",
   "metadata": {},
   "source": [
    "## Step 3: Realloacting counties until population is within bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e2522",
   "metadata": {},
   "source": [
    "#### Helper Functions for reallocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6693aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function: input is a shapefile with 'population' \n",
    "# column. output is a full matrix with SIGNED pop differences\n",
    "def pop_diff_matrix(temp_shapefile):\n",
    "    curr_n_districts = len(temp_shapefile)\n",
    "    pop_diff_mat = np.zeros((curr_n_districts,curr_n_districts))\n",
    "    for i in range(curr_n_districts):\n",
    "        for j in range(curr_n_districts):   \n",
    "            pop_diff_mat[i,j] = temp_shapefile['population'].iloc[i] - temp_shapefile['population'].iloc[j]\n",
    "    \n",
    "    return pop_diff_mat\n",
    "\n",
    "\n",
    "## helper function: given dataframe of movable counties & dataframe \n",
    "# of the district to move to, make a list of relative distances\n",
    "def calculate_rel_dist(border_counties,new_district):\n",
    "    n_border_counties = len(border_counties)\n",
    "    distance_list = np.zeros((n_border_counties,3))\n",
    "\n",
    "    for i in range(n_border_counties):\n",
    "        # old district distance\n",
    "        oldx_dist = border_counties['xcentr_lon_2'].iloc[i] - border_counties['xcentr_lon_1'].iloc[i]\n",
    "        oldy_dist = border_counties['ycentr_lat_2'].iloc[i] - border_counties['ycentr_lat_1'].iloc[i]\n",
    "        distance_list[i,0] = math.sqrt(oldx_dist**2 + oldy_dist**2)\n",
    "\n",
    "        # (potential) new district distance\n",
    "        newx_dist = border_counties['xcentr_lon_2'].iloc[i] - new_district['xcentr_lon'].iloc[0]\n",
    "        newy_dist = border_counties['ycentr_lat_2'].iloc[i] - new_district['ycentr_lat'].iloc[0]\n",
    "        distance_list[i,1] = math.sqrt(newx_dist**2 + newy_dist**2)\n",
    "\n",
    "        ## relative_distance. we'll move the county with highest relative distance\n",
    "        distance_list[i,2] = distance_list[i,0] - distance_list[i,1]\n",
    "\n",
    "    rel_dist = distance_list[:,2]\n",
    "    return rel_dist\n",
    "\n",
    "#helper function to find neighboring districts with the greatest population difference\n",
    "def neighbor_popdiff_fun(df):\n",
    "    #adjacencey matrix for 4 districts\n",
    "    adj_mat_array = adj_mat_calc(df).to_numpy()   \n",
    "\n",
    "    #SIGNED population difference array\n",
    "    pop_diff_array = pop_diff_matrix(df)\n",
    "    # zero out any pairs that aren't adjacent. for numpy, \"*\" is piecewise mult.\n",
    "    neighbor_popdiff = adj_mat_array * pop_diff_array\n",
    "\n",
    "    return neighbor_popdiff\n",
    "\n",
    "\n",
    "#Identify the border counties between the two districts with biggest population difference\n",
    "#return a dataframe with the border counties with a column of relative distances between \n",
    "#the big and small districts\n",
    "def border_counties_df_func(shapef_ia_redist, list_of_districts, list_of_counties,scale_pop_limit_by):\n",
    "    neighbor_popdiff=neighbor_popdiff_fun(shapef_ia_redist)\n",
    "    #popdiff_locs is a list of ordered pairs giving the location of the\n",
    "    #positive values within neighbor_popdiff corresponding to adjacent districts. Note!! Indexed on (0,n-1)!\n",
    "    popdiff_locs=np.argwhere(neighbor_popdiff>0)\n",
    "\n",
    "    big_dist_list=[]\n",
    "    small_dist_list=[]\n",
    "    pop_limit_switch_list=[]\n",
    "    \n",
    "    for i in range(popdiff_locs.shape[0]):\n",
    "        big_dist_index=popdiff_locs[i][0]\n",
    "        big_dist_list.append(big_dist_index)\n",
    "        small_dist_index=popdiff_locs[i][1]\n",
    "        small_dist_list.append(small_dist_index)\n",
    "        pop_limit_switch=scale_pop_limit_by*neighbor_popdiff[big_dist_index][small_dist_index]\n",
    "        pop_limit_switch_list.append(pop_limit_switch)\n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    df['big_dist_index']=big_dist_list #goes from 0 to 3\n",
    "    df['small_dist_index']=small_dist_list #goes from 0 to 3\n",
    "    df['small_dist']=[x+1 for x in small_dist_list] #goes from 1 to 4\n",
    "    df['big_dist']=[x+1 for x in big_dist_list] #goes from 1 to 4\n",
    "    df['pop_limit_switch']=pop_limit_switch_list\n",
    "\n",
    "    df=df.sort_values('pop_limit_switch', ascending=False).reset_index(drop=True)\n",
    "    #Note: pop_limit_switch is a proxy for actual pop limits and we can sort off of\n",
    "    #  this list. But we need to make sure other lists are sorted accordingly\n",
    "\n",
    "    small_dist_list_for_border_counties=[]\n",
    "    big_dist_counties_list=[]\n",
    "    bigdist_movable_list=[]\n",
    "    for j in range(popdiff_locs.shape[0]):\n",
    "        # small_dist_list_for_border_counties=[x-1 for x in small_dist_list]\n",
    "        small_dist_list_for_border_counties.append(list_of_districts[df.loc[j,'small_dist_index']])\n",
    "        big_dist_counties_list.append(list_of_counties[df.loc[j, 'big_dist_index']])\n",
    "        \n",
    "        #update Nov 1\n",
    "        #intersection  and .length finds the length of intersection\n",
    "        #   of each county from the big district with the entirety of the small district\n",
    "        #np.sign turns nonzero entries to 1s\n",
    "        temp_movable_ones = np.sign(big_dist_counties_list[j].intersection(small_dist_list_for_border_counties[j].unary_union).length)\n",
    "        temp_movable_boolean = temp_movable_ones.astype(bool)\n",
    "        bigdist_movable_list.append(big_dist_counties_list[j].loc[temp_movable_boolean].reset_index(drop=True).copy())\n",
    "        # end Nov 1 update\n",
    "\n",
    "        #update the .intersects so that it avoids kitty corners\n",
    "        # bigdist_movable_list.append(big_dist_counties_list[j].loc[big_dist_counties_list[j].intersection(small_dist_list_for_border_counties[j].unary_union)].reset_index(drop=True).copy())\n",
    "        bigdist_movable_list[j]['relative_distance']=calculate_rel_dist(bigdist_movable_list[j], small_dist_list_for_border_counties[j])\n",
    "\n",
    "    return bigdist_movable_list, df['pop_limit_switch'].tolist(), df['small_dist'].tolist(), df['big_dist_index'].tolist()\n",
    "\n",
    "# helper function\n",
    "# input is a shapefile with attributes of single counties (and columns as labeled below)\n",
    "#       usually:  shapef_ia_step3\n",
    "# output is a shapefile with attributes of districts\n",
    "#       usually: shapef_step3_dissolved\n",
    "\n",
    "def dissolve_by_district(county_shapefile):\n",
    "    dissolved_shapefile = county_shapefile.dissolve(\n",
    "        by=\"DISTRICT\",\n",
    "        aggfunc = {\n",
    "            \"population\": \"sum\",\n",
    "            \"xcentr_lon\": \"first\",  #dummy, since we'll recalculate\n",
    "            \"ycentr_lat\": \"first\",\n",
    "            #skip the county_id_string now since we aren't slicing it\n",
    "            # \"county_id_string\": \"sum\", #sum = concatenation here b/c string\n",
    "            \"DISTRICT\": \"first\"\n",
    "        }\n",
    "    )\n",
    "    dissolved_shapefile['xcentr_lon'] = dissolved_shapefile.centroid.x\n",
    "    dissolved_shapefile['ycentr_lat'] = dissolved_shapefile.centroid.y\n",
    "\n",
    "    #the dissolve process has issues with index, so dump for a dummy\n",
    "    dissolved_shapefile = dissolved_shapefile.reset_index(drop=True)\n",
    "\n",
    "    return dissolved_shapefile\n",
    "\n",
    "#gives a range for district size based off of ideal district size\n",
    "def ideal_district_size_func(state_population, n_districts, tolerance):\n",
    "    ideal_district_size=state_population/n_districts\n",
    "    district_maximum=int(ideal_district_size*(1+tolerance))\n",
    "    district_minimum=int(ideal_district_size*(1-tolerance))\n",
    "    return district_minimum, district_maximum\n",
    "\n",
    "\n",
    "#helper function to check for contiguity of big district as switch_func identifies a county\n",
    "#to move from the big district to the small district\n",
    "\n",
    "def big_dist_contiguity_check_func(moving_index, big_dist_df):\n",
    "    df=big_dist_df.loc[big_dist_df['county_id']!=moving_index]\n",
    "    big_dist_laplacian=csgraph.laplacian(adj_mat_calc(df).to_numpy())\n",
    "    return  null_space(big_dist_laplacian).shape[1]\n",
    "\n",
    "\n",
    "#modifying switch_threshold_func to take a list of dataframes as an argument\n",
    "def switch_threshold_func(dataframe_movable_list,max_switches_threshold,switches_range_proportion):\n",
    "    switches_threshold=[]\n",
    "    for j in range(len(dataframe_movable_list)):\n",
    "        # array with all switch counts from the movable county list\n",
    "        num_switches_array = np.array(dataframe_movable_list[j]['num_switches'])\n",
    "\n",
    "        # max and min values from the array\n",
    "        max_switches = max(num_switches_array)\n",
    "        min_switches = min(num_switches_array)\n",
    "        # our chosen threshold for switches: halfway between max and min (floor)\n",
    "        if max_switches<max_switches_threshold:\n",
    "            switches_threshold.append(max_switches)\n",
    "        else:\n",
    "            switches_threshold.append(min_switches + np.ceil((max_switches-min_switches)*switches_range_proportion))\n",
    "    return switches_threshold\n",
    "\n",
    "# switch_func helper function\n",
    "# input is a dataframe with potentially movable counties (and a count of switches)\n",
    "# output is a county to switch: first priority: below threshold of switches (and population)\n",
    "# Then, max relative distance of what's left\n",
    "def switch_func(big_dist_list, list_of_counties, dataframe_movable_list,switches_threshold_list,pop_limit_switch_list,small_dist_list):\n",
    "    for j in range(len(dataframe_movable_list)):\n",
    "        dataframe_sorted = dataframe_movable_list[j].sort_values('relative_distance',ascending=False).copy()\n",
    "        switches_threshold = switches_threshold_list[j]\n",
    "        pop_limit_switch = pop_limit_switch_list[j]\n",
    "        for i in range(dataframe_sorted.shape[0]):\n",
    "            big_dist_index=big_dist_list[j]\n",
    "            if (dataframe_sorted.iloc[i]['num_switches'] <= switches_threshold) & (dataframe_sorted.iloc[i]['population_2']<pop_limit_switch) &(big_dist_contiguity_check_func(dataframe_sorted.iloc[i]['county_id'],list_of_counties[big_dist_index])==1):\n",
    "                return dataframe_sorted.iloc[i]['county_id'], small_dist_list[j]\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main reallocation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da596713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reallocation_func(shapef_ia_fordistricting,shapef_ia_initialdistricting\n",
    "                      ,max_reallocation_limit,n_districts,n_counties,state_population, tolerance):\n",
    "    # adding switch_count to county shapefile which we will be using\n",
    "    shapef_counties_for_realloc = shapef_ia_fordistricting.copy()\n",
    "\n",
    "    # make a column with num_switches\n",
    "    shapef_counties_for_realloc['num_switches'] = np.zeros(shapef_counties_for_realloc.shape[0],dtype=int)\n",
    "\n",
    "    shapef_ia_redist = shapef_ia_initialdistricting.drop(columns=['NAME10', 'COUNTYFP10','county_id','temp_district']).copy()\n",
    "\n",
    "    # make a column with a district #, 1-4\n",
    "    shapef_ia_redist['district_label'] = shapef_ia_redist.index + 1\n",
    "\n",
    "    for k in range(max_reallocation_limit):\n",
    "        # Making separate geodataframes for each district (one district/attribute in each).\n",
    "        list_of_districts=[]\n",
    "        for i in range(n_districts):\n",
    "            list_of_districts.append(shapef_ia_redist.iloc[[i]].reset_index(drop=True))\n",
    "\n",
    "        #the identity overlay takes district n and splits it up by county\n",
    "        list_of_counties=[]\n",
    "        for i in range(n_districts):\n",
    "            list_of_counties.append(list_of_districts[i].overlay(shapef_counties_for_realloc,how='identity',keep_geom_type=True))\n",
    "\n",
    "        #this records the district number each county is assigned to in the first pass\n",
    "        shapef_counties_for_realloc['DISTRICT']=''\n",
    "        for i in range(n_counties):\n",
    "            for j in range(n_districts):\n",
    "                # if i<j:\n",
    "                if shapef_counties_for_realloc.iloc[i]['COUNTYFP10'] in list_of_counties[j]['COUNTYFP10'].tolist():\n",
    "                    shapef_counties_for_realloc.loc[i,'DISTRICT']=j+1\n",
    "\n",
    "        border_counties_df_func_outputs=border_counties_df_func(shapef_ia_redist, list_of_districts, list_of_counties,scale_pop_limit_by)\n",
    "        bigdist_movable_list=border_counties_df_func_outputs[0]\n",
    "        pop_limit_switch_list=border_counties_df_func_outputs[1]\n",
    "        small_district_list = border_counties_df_func_outputs[2]\n",
    "        big_district_list = border_counties_df_func_outputs[3]\n",
    "        \n",
    "        # bigdist_movable\n",
    "        switches_threshold_list=switch_threshold_func(bigdist_movable_list, max_switches_threshold,switches_range_proportion)\n",
    "        switch_func_output=switch_func(big_district_list,list_of_counties, bigdist_movable_list, switches_threshold_list,pop_limit_switch_list,small_district_list)\n",
    "        movingcounty_index=switch_func_output[0]\n",
    "\n",
    "        # Update 99 row dataframe:\n",
    "        shapef_counties_for_realloc.loc[movingcounty_index,'DISTRICT'] = switch_func_output[1]\n",
    "        shapef_counties_for_realloc.loc[movingcounty_index,'num_switches'] = shapef_counties_for_realloc.loc[movingcounty_index,'num_switches']+1\n",
    "\n",
    "        # overwriting old 4 row geodataframe with the new version (dissolved based on updated district number)\n",
    "        shapef_ia_redist = dissolve_by_district(shapef_counties_for_realloc)\n",
    "        \n",
    "        district_size_range=ideal_district_size_func(state_population, n_districts, tolerance)\n",
    "        district_min=district_size_range[0]\n",
    "        district_max=district_size_range[1]\n",
    "\n",
    "        if shapef_ia_redist['population'].max() in range(district_min, district_max+1) and shapef_ia_redist['population'].min() in range(district_min, district_max+1):\n",
    "            break\n",
    "\n",
    "    return shapef_counties_for_realloc, shapef_ia_redist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02daadf",
   "metadata": {},
   "source": [
    "## Compactness measures and drawing district maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb32ac",
   "metadata": {},
   "source": [
    "Princeton Gerrymandering Project uses Reock (minimum bounding circle) and Polsby-Popper (perimeter) in their report cards\n",
    "https://gerrymander.princeton.edu/redistricting-report-card-methodology\n",
    "\n",
    "Polsby-Popper: $PP = \\frac{\\text{Area of district}}{\\text{Area of circle with same perimeter as district}} = 4\\pi \\left(\\frac{\\text{Area of district}}{\\text{(Perimeter of district)}^2}\\right) $\n",
    "\n",
    "Reock: $R = \\frac{\\text{Area of district}}{\\text{Area of MBC}}$\n",
    "\n",
    "(other metrics described here: https://fisherzachary.github.io/public/r-output.html)\n",
    "\n",
    "\n",
    "(Skipping convex hull stuff (for now), but examples are at end of Linear_Programming/Iowa_redistricting_miniset_for_perim.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89f3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is computes compactness scores and appends them as columns to the shapef_ia_redist df\n",
    "def compactness_func(shapef_ia_redist):\n",
    "    shapef_ia_compactness = shapef_ia_redist.copy()\n",
    "    shapef_ia_compactness['area'] = shapef_ia_compactness['geometry'].area\n",
    "    shapef_ia_compactness['perimeter'] = shapef_ia_compactness['geometry'].length\n",
    "    #Polsby-Popper Score\n",
    "    shapef_ia_compactness['PolsbyPopper']=4*math.pi*shapef_ia_compactness['area']/(shapef_ia_compactness['perimeter']**2)\n",
    "    #radius of minimum bounding circle\n",
    "    shapef_ia_compactness['min_bounding_radius']=shapef_ia_compactness['geometry'].minimum_bounding_radius()\n",
    "    #Reock Score\n",
    "    shapef_ia_compactness['Reock']=shapef_ia_compactness['area']/(math.pi*(shapef_ia_compactness['min_bounding_radius']**2))\n",
    "    \n",
    "    return shapef_ia_compactness\n",
    "\n",
    "color_dict = { 1 : '#3995ff',\n",
    "               2 : '#ff8539',\n",
    "               3 : '#ffe839',\n",
    "               4 : '#d139ff',\n",
    "               }\n",
    "\n",
    "def distmap_by_county(map_data,data_label):\n",
    "    plot_distmap = (\n",
    "        ggplot(map_data)\n",
    "    + geom_map(aes(fill='DISTRICT')\n",
    "        ,show_legend=True\n",
    "        )\n",
    "    + geom_label(aes(x='xcentr_lon', y='ycentr_lat', label=data_label,size=2)\n",
    "        , show_legend=False)\n",
    "    + theme_minimal()\n",
    "    + theme(axis_text_x=element_blank(),\n",
    "            axis_text_y=element_blank(),\n",
    "            axis_title_x=element_blank(),\n",
    "            axis_title_y=element_blank(),\n",
    "            axis_ticks=element_blank(),\n",
    "            panel_grid_major=element_blank(),\n",
    "            panel_grid_minor=element_blank(),\n",
    "            plot_background = element_rect(fill = 'white')       #whole png area\n",
    "            )\n",
    "    + scale_fill_manual(values=color_dict)  #require district i to always be color i\n",
    "    )\n",
    "    return plot_distmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate district maps based on random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting thresholds for helper functions\n",
    "scale_pop_limit_by=6\n",
    "max_switches_threshold=5\n",
    "switches_range_proportion=.75\n",
    "n_counties = 99\n",
    "n_districts = 4\n",
    "tolerance = .01\n",
    "max_reallocation_limit = 100  #for loop max on step 3\n",
    "district_size=ideal_district_size_func(state_population, n_districts, tolerance)\n",
    "district_min=district_size[0]\n",
    "district_max=district_size[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22c2faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_to_rerun_first_third=[0, 2, 4, 5, 6, 7, 8, 10,13,14\n",
    "                            ,15,16,17,18,19,21,23,25,28,29\n",
    "                            ,30,33,34,35,37,38,40,41,43,44\n",
    "                            ,47,48,49,50,55,56,57,58,59,60\n",
    "                            ,65,66,68,72,73,75,76,77,78,81\n",
    "                            ,84,85,86,87,88,92]\n",
    "seeds_to_rerun_second_third=[93,94,98,99,100,101,104,106,107,108\n",
    "                             ,111,113,114,117,119,120,122,123,125,127\n",
    "                             ,128,129,130,131,132,133,134,135,136,137\n",
    "                             ,138,139,140,141,142,143,144,147,149,151\n",
    "                             ,152,153,154,156,157,159,160,161,163,164\n",
    "                             ,165,166,171,172,173,176]\n",
    "seeds_to_rerun_last_third=[177,179,181,184,185,186,189,190,191,192\n",
    "                            ,194,196,197,199,200,203,204,208,209,212\n",
    "                            ,213,214,215,216,217,218,219,220,222,224\n",
    "                            ,225,227,228,229,230,231,232,233,234,235\n",
    "                            ,237,238,239,240,241,242,243,244,246,247\n",
    "                            ,249,250,252,254,255,256,258,259]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed_number in range(260,300):\n",
    "    random.seed(seed_number)\n",
    "    shapef_ia_initialdistricting = initial_alloc_func(shapef_ia_fordistricting)\n",
    "    reallocation_output = reallocation_func(shapef_ia_fordistricting,shapef_ia_initialdistricting\n",
    "                                        ,max_reallocation_limit,n_districts,n_counties,state_population, tolerance)\n",
    "    shapef_counties_for_realloc = reallocation_output[0]\n",
    "    shapef_ia_redist = reallocation_output[1]\n",
    "    shapef_ia_compactness=compactness_func(shapef_ia_redist)  \n",
    "\n",
    "    district_map=distmap_by_county(shapef_counties_for_realloc,'county_id')\n",
    "\n",
    "    #all the exports\n",
    "    if shapef_ia_redist['population'].max() in range(district_min, district_max+1) and shapef_ia_redist['population'].min() in range(district_min, district_max+1):\n",
    "        #kth iteration of generating maps. Change 0 to k for future use\n",
    "        iter_number=str(seed_number).rjust(3,'0')\n",
    "\n",
    "         #export image of district as png\n",
    "        district_map.save(\"district_maps/seed_{}_district_map.png\".format(iter_number), verbose=False)\n",
    "\n",
    "        #exporting dataframe with 99 county gpd with district allocation for winner     analysis\n",
    "        #Calculate winners with winner_tabulation() in a separate notebook for each file    in ./allocation_by_county\n",
    "        shapef_counties_for_realloc.to_csv('allocation_by_county/{}.csv'.format('seed_' +str(iter_number)+'_by_county'), index=False, header=True)\n",
    "\n",
    "        #exporting dataframe with district gpd for compactness analysis. Pull   Polsby-Popper and Reock scores for analysis in a separate notebook\n",
    "        shapef_ia_compactness.to_csv('allocation_by_district/{}.csv'.format('seed_'+str (iter_number)+'_by_district'), index=False, header=True)\n",
    "    else:\n",
    "        print('seed ', seed_number,' fails to converge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran on 12/6/23 for seed_number in range(5) and it finished in 10m 38.0s. Ran up to seed 64 in 507 minutes\n",
    "\n",
    "Ran on 12/7/23 for seeds in range(16,100) for switch_threshold=5. Ran on 2/21/24 for seeds in range(100,200) for 285 minutes.\n",
    "\n",
    "7/31/25:\n",
    "- Decreased maximum allocation limit to 100.\n",
    "- Ran 56 seeds in seeds_to_rerun_first_third for 138 minutes\n",
    "- Ran 56 seeds in seeds_to_rerun_second_third for ~130 minutes\n",
    "- Ran 58 seeds in seeds_to_rerun_last_third for 183 minutes\n",
    "\n",
    "8/7/25:\n",
    "- Ran seeds in range(260, 300) for 85 minutes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "857970f990130bbcaee778cf1846f7875676d945310dca1379fe4b5ef3d258a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
